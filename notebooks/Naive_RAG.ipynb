{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46e1a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\" # For macOS users to avoid OpenMP error, specifically for FIASS\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "381eb78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3acb440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 15 pages from '../resources/pdfs/attention.pdf'\n",
      "\n",
      "--- First Document Preview ---\n",
      "Content (first 500 chars): Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmar∗\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreit∗\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones∗\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomez∗ †\n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu\n",
      "Łukasz ...\n",
      "\n",
      "Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../resources/pdfs/attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Total characters across all pages: 39,587\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"../resources/pdfs/attention.pdf\"  # Change this to your PDF file path\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"⚠️  ERROR: File '{pdf_path}' not found!\")\n",
    "    print(\"Please update the pdf_path variable with your PDF file location.\")\n",
    "else:\n",
    "    # Initialize the PDF loader\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    \n",
    "    # Load all pages from the PDF\n",
    "    # Each page becomes a separate Document object\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Display information about loaded documents\n",
    "    print(f\"✓ Loaded {len(documents)} pages from '{pdf_path}'\")\n",
    "    print(f\"\\n--- First Document Preview ---\")\n",
    "    print(f\"Content (first 500 chars): {documents[0].page_content[:500]}...\")\n",
    "    print(f\"\\nMetadata: {documents[0].metadata}\")\n",
    "    print(f\"\\nTotal characters across all pages: {sum(len(doc.page_content) for doc in documents):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bee6bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Split 15 documents into 49 chunks\n",
      "\n",
      "Average chunk size: 873 characters\n",
      "\n",
      "--- Chunk Examples ---\n",
      "\n",
      "Chunk 1 (length: 986 chars):\n",
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "...\n",
      "Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../resources/pdfs/attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Chunk 2 (length: 944 chars):\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to\n",
      "be superior in quality while being more pa...\n",
      "Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../resources/pdfs/attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Chunk 3 (length: 986 chars):\n",
      "∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\n",
      "the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Tra...\n",
      "Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../resources/pdfs/attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,        # Maximum characters per chunk (roughly 200-250 tokens)\n",
    "    chunk_overlap=128,      # Characters overlap between chunks (maintains context)\n",
    "    length_function=len,    # Function to measure chunk length\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # Try to split on paragraphs first, then lines, etc.\n",
    ")\n",
    "\n",
    "# Split the documents into chunks\n",
    "# This creates smaller, manageable pieces while preserving semantic meaning\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Display splitting results\n",
    "print(f\"✓ Split {len(documents)} documents into {len(chunks)} chunks\")\n",
    "print(f\"\\nAverage chunk size: {sum(len(chunk.page_content) for chunk in chunks) / len(chunks):.0f} characters\")\n",
    "\n",
    "# Preview a few chunks\n",
    "print(f\"\\n--- Chunk Examples ---\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"\\nChunk {i+1} (length: {len(chunk.page_content)} chars):\")\n",
    "    print(f\"{chunk.page_content[:200]}...\")\n",
    "    print(f\"Metadata: {chunk.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e431f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gemini Embeddings\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"gemini-embedding-001\",  # Latest, cost-effective embedding model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f6e108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FAISS index from 49 chunks...\n",
      "This may take a minute depending on the number of chunks...\n",
      "✓ FAISS vector store created successfully!\n",
      "✓ Indexed 49 document chunks\n",
      "✓ Vector store saved to '../vectorstores/faiss_index'\n",
      "\n",
      "ℹ️  You can reload this index later using: FAISS.load_local('../vectorstores/faiss_index', embeddings)\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS vector store from document chunks\n",
    "# This step converts each chunk to an embedding and stores it\n",
    "print(f\"Creating FAISS index from {len(chunks)} chunks...\")\n",
    "print(\"This may take a minute depending on the number of chunks...\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=chunks,      # Our split document chunks\n",
    "    embedding=gemini_embeddings   # Gemini embedding model\n",
    ")\n",
    "\n",
    "print(f\"✓ FAISS vector store created successfully!\")\n",
    "print(f\"✓ Indexed {len(chunks)} document chunks\")\n",
    "\n",
    "# Save the vector store to disk for later use\n",
    "# This allows you to reload the index without re-processing documents\n",
    "vectorstore_path = \"../vectorstores/faiss_index\"\n",
    "vectorstore.save_local(vectorstore_path)\n",
    "print(f\"✓ Vector store saved to '{vectorstore_path}'\")\n",
    "print(f\"\\nℹ️  You can reload this index later using: FAISS.load_local('{vectorstore_path}', embeddings)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f687d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever from the vector store\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",    # Use cosine similarity for search\n",
    "    search_kwargs={\"k\": 4}        # Retrieve top 4 most relevant chunks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35704096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Google Gemini model\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.0,\n",
    "    max_output_tokens=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7655e8f8",
   "metadata": {},
   "source": [
    "## Retrieved Docs from the VDB + Context + Prompt ---> LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "448b4e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAG chain created successfully using LangChain 1.0+ LCEL!\n",
      "\n",
      "RAG Pipeline Flow:\n",
      "  1. User provides a query\n",
      "  2. Retriever finds top 4 relevant chunks\n",
      "  3. Chunks are formatted as context\n",
      "  4. Context + question are formatted with prompt template\n",
      "  5. LLM generates answer based on context\n",
      "  6. Answer is parsed and returned to user\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt template for the RAG system\n",
    "# This tells the LLM how to use the retrieved context\n",
    "system_prompt = (\n",
    "    \"You are a helpful assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer based on the context, say that you don't know. \"\n",
    "    \"Keep the answer concise and accurate.\\n\\n\"\n",
    "    \"Context: {context}\\n\\n\"\n",
    "    \"Question: {question}\"\n",
    ")\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = ChatPromptTemplate.from_template(system_prompt)\n",
    "\n",
    "# Helper function to format documents\n",
    "def format_docs(docs):\n",
    "    \"\"\"Format retrieved documents into a single string.\"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Build the RAG chain using LangChain 1.0+ LCEL (LangChain Expression Language)\n",
    "# This uses the pipe operator (|) to chain components together\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,  # Retrieve docs and format them\n",
    "        \"question\": RunnablePassthrough()      # Pass through the question\n",
    "    }\n",
    "    | prompt           # Format with prompt template\n",
    "    | llm              # Generate answer with LLM\n",
    "    | StrOutputParser() # Parse output to string\n",
    ")\n",
    "\n",
    "print(\"✓ RAG chain created successfully using LangChain 1.0+ LCEL!\")\n",
    "print(\"\\nRAG Pipeline Flow:\")\n",
    "print(\"  1. User provides a query\")\n",
    "print(\"  2. Retriever finds top 4 relevant chunks\")\n",
    "print(\"  3. Chunks are formatted as context\")\n",
    "print(\"  4. Context + question are formatted with prompt template\")\n",
    "print(\"  5. LLM generates answer based on context\")\n",
    "print(\"  6. Answer is parsed and returned to user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ce8adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the main topic or subject of this document?\n",
      "\n",
      "Processing...\n",
      "\n",
      "================================================================================\n",
      "ANSWER:\n",
      "================================================================================\n",
      "The main topic of this document is the attention mechanism in neural networks, specifically its visualization and application in tasks like anaphora resolution and following long-distance dependencies, often in the context of neural machine translation.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "SOURCE DOCUMENTS USED:\n",
      "================================================================================\n",
      "\n",
      "Document 1:\n",
      "  Source: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../resources/pdfs/attention.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14'}\n",
      "  Content: Input-Input Layer5\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "sh...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Document 2:\n",
      "  Source: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../resources/pdfs/attention.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9'}\n",
      "  Content: (section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\n",
      "remained unchanged from the English-to-German base translation model. During inference, we\n",
      "9...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Document 3:\n",
      "  Source: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../resources/pdfs/attention.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13'}\n",
      "  Content: Attention Visualizations\n",
      "Input-Input Layer5\n",
      "It\n",
      "is\n",
      "in\n",
      "this\n",
      "spirit\n",
      "that\n",
      "a\n",
      "majority\n",
      "of\n",
      "American\n",
      "governments\n",
      "have\n",
      "passed\n",
      "new\n",
      "laws\n",
      "since\n",
      "2009\n",
      "making\n",
      "the\n",
      "registration\n",
      "or\n",
      "voting\n",
      "process\n",
      "more\n",
      "difficult\n",
      ".\n",
      "<EOS...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Document 4:\n",
      "  Source: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '../resources/pdfs/attention.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11'}\n",
      "  Content: arXiv:1703.10722, 2017.\n",
      "[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\n",
      "Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\n",
      "arXi...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example Query 1: General question about the document\n",
    "query1 = \"What is the main topic or subject of this document?\"\n",
    "\n",
    "print(f\"Query: {query1}\")\n",
    "print(\"\\nProcessing...\\n\")\n",
    "\n",
    "# With LangChain 1.0+, we invoke the chain with the question directly\n",
    "answer = rag_chain.invoke(query1)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANSWER:\")\n",
    "print(\"=\" * 80)\n",
    "print(answer)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# To see which documents were retrieved, we can call the retriever separately\n",
    "print(\"\\nSOURCE DOCUMENTS USED:\")\n",
    "print(\"=\" * 80)\n",
    "retrieved_docs = retriever.invoke(query1)\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"  Source: {doc.metadata}\")\n",
    "    print(f\"  Content: {doc.page_content[:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0804e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
